# CosyVoice3部署指南
## 环境要求

- **Python**: 3.10
- **GPU**: NVIDIA GPU（推荐，>=8GB显存）
- **OS**: Linux ubuntu 18.04 / Windows

## 快速安装

### 1. 克隆项目

```bash
git clone https://github.com/3uyuan1ee/TFG_ui.git
cd TFG_ui
git submodule update --init --recursive
```

### 2. 创建虚拟环境

```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate
```

### 3. 安装依赖

```bash
cd EchOfU
pip install -r requirements.txt
winget install ffmpeg

```

Ubuntu/Debian

```bash
# 基础安装
sudo apt-get update
sudo apt-get install -y ffmpeg

# 完整安装（包含所有编解码器）
sudo apt-get install -y ffmpeg libavcodec-extra

# 验证安装
ffmpeg -version
```

**国内用户加速**:
```bash
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
```

### 4. 下载模型

**方法1: 自动下载（运行时会自动下载）**
如果要使用自动下载，请务必关闭flask的调试模式！

**方法2: 手动下载**
```python
from modelscope import snapshot_download

# 下载 CosyVoice3-2512 模型
snapshot_download('FunAudioLLM/Fun-CosyVoice3-0.5B-2512',
                   local_dir='EchOfU/CosyVoice/pretrained_models/Fun-CosyVoice3-0.5B-2512')
```

### 5. 启动服务

使用IDE可能会导入失败，要将项目根设置为EchOfU
```bash
cd EchOfU
python app.py
```

访问: http://localhost:5001

## 快速使用

### Web界面

1. 打开浏览器访问 http://localhost:5001
2. 进入"音频克隆"页面
3. 上传参考音频（或录制）
4. 输入要合成的文本
5. 点击生成


## 常见问题

### Q: 编译错误（grpcio等）

```bash
# 使用预编译版本
pip install --no-build-isolation grpcio==1.57.0 grpcio-tools==1.57.0
```

### Q: 子模块初始化失败

```bash
cd TFG_ui
git submodule update --init --recursive --depth=1
```

### Q: 内存不足

```python
# 使用小模型或禁用VLLM
service = CosyService(load_vllm=False)
```

### Q: macOS 编译问题

```bash
# 安装系统依赖
brew install cmake sox
xcode-select --install
```

### Q: 如何启用vllm加速

在backend/voice_generator.py中修改CosyService初始化参数：
```python
# VLLM 加速（推荐，需要GPU）
service = CosyService(load_vllm=True)

# VLLM + FP16（最佳性能）
service = CosyService(load_vllm=True, fp16=True)
## 目录结构

```
EchOfU/
├── app.py                 # Flask 应用入口
├── requirements.txt       # 所有依赖（已包含 CosyVoice + Matcha-TTS）
├── backend/              # 后端模块
│   ├── CV_clone.py      # CosyVoice 服务
│   └── ...
├── static/              # 静态资源
│   ├── voices/         # 音频文件
│   └── videos/         # 视频文件
└── CosyVoice/          # CosyVoice 子模块
    └── pretrained_models/  # 模型存放目录
```

---

# ER-NeRF 视频生成部署指南

### 硬件要求

| 组件 | 最低要求 | 推荐配置 |
|------|----------|----------|
| **GPU** | NVIDIA RTX 3090 (24GB) | NVIDIA RTX 4090 (24GB) 或 A100 (40GB+) |
| **CPU** | 8核心 | 16核心+ |
| **内存** | 32GB | 64GB+ |
| **存储** | 100GB SSD | 500GB NVMe SSD |

### 软件要求

| 软件 | 版本要求 |
|------|----------|
| **操作系统** | Ubuntu 18.04 |
| **NVIDIA Driver** | ≥ 470.x |
| **Docker** | ≥ 20.10 |
| **NVIDIA Container Toolkit** | ≥ 1.6.0 |

### ️ 重要说明

-  **不支持macOS** (Mac无法运行CUDA)
-  **Windows支持有限** (Windows支持有限，仅通过WSL2)
-  **支持Linux** (完整支持)

**推荐方案**: 使用Linux服务器或云GPU平台

## 快速部署（云GPU平台）

### 方案1: AutoDL（推荐，国内用户）

```bash
# 1. 注册AutoDL: https://www.autodl.com/
# 2. 租用RTX 4090 (~1-2元/小时)
# 3. 在AutoDL的Jupyter终端中执行:

# 克隆项目
git clone <your-repo-url>
cd TFG_ui/EchOfU

# 运行自动部署脚本
bash scripts/start_ernerf_docker.sh setup

# 等待构建完成（30-60分钟）

# 启动Backend服务
export USE_DOCKER_FOR_ERNERF=true
python app.py

# 4. 在Mac上访问AutoDL提供的外网地址
```

### 方案2: 其他云平台

**Google Colab Pro** / **AWS** / **GCP** / **Azure**

```bash
# 在云平台的终端中执行
git clone <your-repo-url>
cd TFG_ui/EchOfU

# 完整设置（自动）
bash scripts/start_ernerf_docker.sh setup

# 启动服务
python app.py
```

## 本地Linux服务器部署

### 步骤1: 准备服务器环境

```bash
# 更新系统
sudo apt-get update && sudo apt-get upgrade -y

# 安装基础工具
sudo apt-get install -y \
    git \
    wget \
    curl \
    vim \
    build-essential

# 安装Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# 安装NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
    sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# 验证NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:11.3.1-base-ubuntu18.04 nvidia-smi
```

### 步骤2: 下载项目代码

```bash
# 克隆项目
git clone https://github.com/3uyuan1ee/TFG_ui.git
cd TFG_ui/EchOfU

# 初始化子模块
git submodule update --init --recursive
```

### 步骤3: 准备BFM模型（重要）

#### 3.1 申请BFM模型

1. 访问: https://faces.dmi.unibas.ch/bfm/main.php?nav=1-1-0&id=details
2. 使用学术邮箱注册账号
3. 申请下载权限（通常1-3个工作日）
4. 下载BFM模型文件

#### 3.2 放置并转换模型

```bash
# 创建模型目录
mkdir -p ./bfm_models

# 将下载的文件放到该目录
# 文件名通常是: BFM_model_front.mat

# 使用Docker转换（需要先构建镜像）
docker compose -f docker-compose.ernerf.yml run --rm ernerf convert-bfm

# 验证转换结果
ls ./bfm_models/
# 应该看到:
# exp_para.npy
# tex_para.npy
# shape_para.npy
```

### 步骤4: 构建Docker镜像

```bash
# 方式1: 使用脚本（推荐）
bash scripts/start_ernerf_docker.sh build

# 方式2: 直接使用docker compose
docker compose -f docker-compose.ernerf.yml build
```

**预计时间**: 30-60分钟

### 步骤5: 启动服务

```bash
# 1. 启动ER-NeRF容器
docker compose -f docker-compose.ernerf.yml up -d

# 2. 查看容器状态
docker compose -f docker-compose.ernerf.yml ps

# 3. 查看日志
docker compose -f docker-compose.ernerf.yml logs -f
```

### 步骤6: 验证安装

```bash
# 运行环境验证
docker compose -f docker-compose.ernerf.yml run --rm ernerf python -c "
import torch
import torch3d
print('=' * 50)
print('ER-NeRF 环境验证')
print('=' * 50)
print(f'PyTorch: {torch.__version__}')
print(f'CUDA可用: {torch.cuda.is_available()}')
print(f'GPU数量: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
print('pytorch3d: OK')
print('=' * 50)
print('✓ 所有检查通过！')
"
```

## Backend集成

### 环境变量配置

```bash
# 使用Docker模式（推荐，默认）
export USE_DOCKER_FOR_ERNERF=true

# 使用直接调用模式（需要本地ER-NeRF环境）
export USE_DOCKER_FOR_ERNERF=false
```

### 安装Backend依赖

```bash
# 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Linux
# venv\Scripts\activate  # Windows

# 安装依赖
pip install -r requirements.txt

# 国内用户加速
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
```

### 启动Backend服务

```bash
cd EchOfU

# 确保Docker模式已启用
export USE_DOCKER_FOR_ERNERF=true

# 启动Flask服务
python app.py

# 访问: http://localhost:5001 或 http://服务器IP:5001
```

## 完整使用流程

### 1. 训练ER-NeRF模型

#### 方式A: 通过Web界面

1. 访问 http://服务器IP:5001
2. 进入"训练"页面
3. 上传参考视频
4. 选择模型: ER-NeRF
5. 输入任务ID
6. 点击"开始训练"

#### 方式B: 通过Docker命令

```bash
# 1. 数据预处理
docker compose -f docker-compose.ernerf.yml run --rm ernerf \
    preprocess /path/to/video.mp4 my_task

# 2. 训练（自动完成三阶段）
docker compose -f docker-compose.ernerf.yml run --rm ernerf \
    train data/my_task models/ER-NeRF/my_task
```

### 2. 使用ER-NeRF生成视频

#### 方式A: 通过Web界面

1. 进入"视频生成"页面
2. 选择ER-NeRF模型
3. 上传参考音频或输入文本
4. 点击"生成视频"

#### 方式B: 通过Docker命令

```bash
# 1. 提取音频特征
docker compose -f docker-compose.ernerf.yml run --rm ernerf \
    extract-features /path/to/audio.wav

# 2. 生成视频
docker compose -f docker-compose.ernerf.yml run --rm ernerf \
    test data/my_task models/ER-NeRF/my_task /path/to/audio.npy
```

## 训练时间估算

| 阶段 | RTX 3090 | RTX 4090 | 说明 |
|------|----------|----------|------|
| 预处理 | 2-4小时 | 1-2小时 | 提取特征、landmarks等 |
| 头部训练 | 2-3小时 | 1-2小时 | 100k iterations |
| 嘴唇微调 | 1-2小时 | 0.5-1小时 | 125k iterations |
| 躯干训练 | 3-4小时 | 2-3小时 | 200k iterations |
| **总计** | **8-13小时** | **5-8小时** | 完整流程 |

## 常见问题排查

### Q1: Docker构建失败

```bash
# 清理Docker缓存
docker system prune -a

# 重新构建
docker compose -f docker-compose.ernerf.yml build --no-cache
```

### Q2: CUDA错误

```bash
# 检查NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:11.3.1-base-ubuntu18.04 nvidia-smi

# 重新安装nvidia-container-toolkit
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### Q3: GPU内存不足

```bash
# 检查GPU内存
nvidia-smi

# 清理GPU缓存
sudo fuser -v /dev/nvidia*
sudo kill -9 $(sudo fuser /dev/nvidia* | awk '{print $2}')

# 或降低batch size（修改训练参数）
```

### Q4: 预处理卡住

```bash
# 预处理可能需要几小时，这是正常的
# 查看进程状态
docker compose -f docker-compose.ernerf.yml top ernerf

# 查看详细日志
docker compose -f docker-compose.ernerf.yml logs -f ernerf
```

## 监控和维护

### 查看系统资源

```bash
# GPU使用率
watch -n 1 nvidia-smi

# 磁盘使用
df -h

# 内存使用
free -h

# Docker资源
docker stats
```

### 查看日志

```bash
# Backend日志
tail -f logs/access.log
tail -f logs/error.log

# Docker日志
docker compose -f docker-compose.ernerf.yml logs -f ernerf
```

### 备份重要数据

```bash
# 备份模型
tar -czf models_backup_$(date +%Y%m%d).tar.gz models/ER-NeRF/

# 备份BFM模型
tar -czf bfm_backup.tar.gz bfm_models/

# 备份配置
tar -czf config_backup.tar.gz .env docker-compose*.yml
```

## 文档索引

- **[完整部署指南](docker/ERNERF_DEPLOYMENT.md)** - 详细的部署步骤
- **[Docker使用指南](docker/ERNERF_DOCKER.md)** - Docker命令详解
- **[Backend集成指南](docker/ERNERF_BACKEND_INTEGRATION.md)** - 开发集成说明

